{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Multiplie Multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (2923, 11) (2923,)\n",
      "Testing set: (627, 11) (627,)\n",
      "Validation set: (627, 11) (627,)\n",
      "\n",
      "Training set:\n",
      "      Length  Diameter  Height  Whole weight  Shucked weight  Viscera weight  \\\n",
      "2830   0.525     0.430   0.135        0.8435          0.4325          0.1800   \n",
      "925    0.430     0.325   0.100        0.3645          0.1575          0.0825   \n",
      "3845   0.455     0.350   0.105        0.4160          0.1625          0.0970   \n",
      "547    0.205     0.155   0.045        0.0425          0.0170          0.0055   \n",
      "2259   0.590     0.465   0.160        1.1005          0.5060          0.2525   \n",
      "\n",
      "      Shell weight   Age  Sex_F  Sex_I  Sex_M  \n",
      "2830        0.1815  10.5    1.0    0.0    0.0  \n",
      "925         0.1050   8.5    0.0    1.0    0.0  \n",
      "3845        0.1450  12.5    0.0    0.0    1.0  \n",
      "547         0.0155   8.5    0.0    0.0    1.0  \n",
      "2259        0.2950  14.5    1.0    0.0    0.0  \n",
      "\n",
      "Testing set:\n",
      "      Length  Diameter  Height  Whole weight  Shucked weight  Viscera weight  \\\n",
      "3142   0.215     0.165   0.055        0.0590          0.0265          0.0125   \n",
      "752    0.605     0.460   0.170        1.1220          0.3470          0.3045   \n",
      "1188   0.690     0.540   0.155        1.4540          0.6240          0.3105   \n",
      "3740   0.650     0.500   0.170        1.4045          0.6940          0.3180   \n",
      "2586   0.555     0.425   0.140        0.9630          0.4400          0.2240   \n",
      "\n",
      "      Shell weight   Age  Sex_F  Sex_I  Sex_M  \n",
      "3142        0.0185   6.5    0.0    1.0    0.0  \n",
      "752         0.3150  14.5    1.0    0.0    0.0  \n",
      "1188        0.3900  10.5    1.0    0.0    0.0  \n",
      "3740        0.3235  12.5    1.0    0.0    0.0  \n",
      "2586        0.2400   8.5    1.0    0.0    0.0  \n",
      "\n",
      "Validation set:\n",
      "      Length  Diameter  Height  Whole weight  Shucked weight  Viscera weight  \\\n",
      "2148   0.415     0.310   0.090        0.3245          0.1305          0.0735   \n",
      "2303   0.580     0.455   0.120        0.9400          0.3990          0.2570   \n",
      "270    0.640     0.525   0.215        1.7790          0.4535          0.2855   \n",
      "3409   0.395     0.310   0.095        0.3130          0.1310          0.0720   \n",
      "3654   0.530     0.420   0.140        0.6765          0.2560          0.1855   \n",
      "\n",
      "      Shell weight   Age  Sex_F  Sex_I  Sex_M  \n",
      "2148         0.115   9.5    0.0    0.0    1.0  \n",
      "2303         0.265  12.5    1.0    0.0    0.0  \n",
      "270          0.550  23.5    1.0    0.0    0.0  \n",
      "3409         0.093   8.5    0.0    1.0    0.0  \n",
      "3654         0.208  10.5    0.0    1.0    0.0  \n",
      "\n",
      "First 5 rows of the scaled training set:\n",
      " [[-0.00954585  0.20680221 -0.12072394  0.01457825  0.31105444 -0.02098237\n",
      "  -0.42540763 -0.30383887  1.46390258 -0.67933791 -0.75989604]\n",
      " [-0.80318028 -0.85404855 -0.94465076 -0.95900917 -0.9194155  -0.91375895\n",
      "  -0.96974532 -0.92144737 -0.68310557  1.47202148 -0.75989604]\n",
      " [-0.59432912 -0.60146504 -0.82694693 -0.85433328 -0.89704332 -0.78098705\n",
      "  -0.68512431  0.31376963 -0.68310557 -0.67933791  1.31596949]\n",
      " [-2.68284079 -2.57161646 -2.2393929  -1.61348756 -1.54807379 -1.61882353\n",
      "  -1.60658483 -0.92144737 -0.68310557 -0.67933791  1.31596949]\n",
      " [ 0.53346719  0.56041914  0.46779521  0.53694144  0.6399255   0.64287714\n",
      "   0.38220449  0.93137813  1.46390258 -0.67933791 -0.75989604]]\n",
      "\n",
      "First 5 rows of the scaled testing set:\n",
      " [[-2.59930032 -2.47058306 -2.00398524 -1.57995062 -1.50556664 -1.55472675\n",
      "  -1.58523826 -1.53905587 -0.68310557  1.47202148 -0.75989604]\n",
      " [ 0.65877789  0.50990243  0.70320287  0.58064109 -0.07150985  1.11902465\n",
      "   0.524515    0.93137813  1.46390258 -0.67933791 -0.75989604]\n",
      " [ 1.36887186  1.31816968  0.35009138  1.25544489  1.16790897  1.17396475\n",
      "   1.05817939 -0.30383887  1.46390258 -0.67933791 -0.75989604]\n",
      " [ 1.03470999  0.91403606  0.70320287  1.15483408  1.4811195   1.24263987\n",
      "   0.58499696  0.31376963  1.46390258 -0.67933791 -0.75989604]\n",
      " [ 0.24107555  0.15628551 -0.00302011  0.25746697  0.34461272  0.38191168\n",
      "  -0.0091494  -0.92144737  1.46390258 -0.67933791 -0.75989604]]\n",
      "\n",
      "First 5 rows of the scaled validation set:\n",
      " [[-9.28490985e-01 -1.00559866e+00 -1.18005842e+00 -1.04031083e+00\n",
      "  -1.04022528e+00 -9.96169094e-01 -8.98590066e-01 -6.12643122e-01\n",
      "  -6.83105567e-01 -6.79337913e-01  1.31596949e+00]\n",
      " [ 4.49926719e-01  4.59385730e-01 -4.73835436e-01  2.10718517e-01\n",
      "   1.61160833e-01  6.84082213e-01  1.68738731e-01  3.13769628e-01\n",
      "   1.46390258e+00 -6.79337913e-01 -7.59896036e-01]\n",
      " [ 9.51169521e-01  1.16661957e+00  1.76253735e+00  1.91602091e+00\n",
      "   4.05017604e-01  9.45047675e-01  2.19666344e+00  3.71061638e+00\n",
      "   1.46390258e+00 -6.79337913e-01 -7.59896036e-01]\n",
      " [-1.09557192e+00 -1.00559866e+00 -1.06235459e+00 -1.06368506e+00\n",
      "  -1.03798806e+00 -1.00990412e+00 -1.05513162e+00 -9.21447372e-01\n",
      "  -6.83105567e-01  1.47202148e+00 -7.59896036e-01]\n",
      " [ 3.22243847e-02  1.05768807e-01 -3.02011198e-03 -3.24856192e-01\n",
      "  -4.78683540e-01  2.93793877e-02 -2.36846212e-01 -3.03838872e-01\n",
      "  -6.83105567e-01  1.47202148e+00 -7.59896036e-01]]\n",
      "Training Set: 2923 samples\n",
      "Testing Set: 627 samples\n",
      "Validation Set: 627 samples\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18428\\4210374767.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "%run DataSplitting.ipynb\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.activations import linear, relu, sigmoid\n",
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('./deeplearning.mplstyle')\n",
    "\n",
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "tf.autograph.set_verbosity(0)\n",
    "\n",
    "# from public_tests import *\n",
    "\n",
    "# from autils import *\n",
    "# from lab_utils_softmax import plt_softmax\n",
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_softmax(z):\n",
    "    ### START CODE HERE ###\n",
    "    ez = np.exp(z)\n",
    "    a = ez/np.sum(ez)\n",
    "    ### END CODE HERE ###\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21168\\82078700.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_seed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1234\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# for consistent results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m model = Sequential(\n\u001b[0;32m      3\u001b[0m     [\n\u001b[0;32m      4\u001b[0m         \u001b[1;31m### START CODE HERE ###\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInputLayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1234) # for consistent results\n",
    "model = Sequential(\n",
    "    [\n",
    "        ### START CODE HERE ###\n",
    "        tf.keras.layers.InputLayer((11,)),\n",
    "        tf.keras.layers.Dense(3, activation=\"relu\", name=\"L1\"),\n",
    "        tf.keras.layers.Dense(2, activation=\"linear\", name=\"L2\")\n",
    "        ### END CODE HERE ###\n",
    "    ], name = \"my_model\"\n",
    ")\n",
    "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine Layer Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[layer1, layer2] = model.layers\n",
    "#### Examine Weights shapes\n",
    "W1,b1 = layer1.get_weights()\n",
    "W2,b2 = layer2.get_weights()\n",
    "print(f\"W1 shape = {W1.shape}, b1 shape = {b1.shape}\")\n",
    "print(f\"W2 shape = {W2.shape}, b2 shape = {b2.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_scaled,y_train,\n",
    "    epochs=40\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_of_342 = X_train_scaled[342]\n",
    "prediction = model.predict(age_of_342.reshape(1,11))  # prediction\n",
    "print(f\" predicting a Two: \\n{prediction}\")\n",
    "print(f\" Largest Prediction index: {np.argmax(prediction)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_p = tf.nn.softmax(prediction)\n",
    "\n",
    "print(f\" predicting a Two. Probability vector: \\n{prediction_p}\")\n",
    "print(f\"Total of predictions: {np.sum(prediction_p):0.3f}\")\n",
    "\n",
    "yhat = np.argmax(prediction_p)\n",
    "print(f\"np.argmax(prediction_p): {yhat}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
