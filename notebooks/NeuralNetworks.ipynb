{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Multiple Multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run DataSplitting.ipynb\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.activations import linear, relu, sigmoid\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "# %matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "tf.autograph.set_verbosity(0)\n",
    "# from public_tests import *\n",
    "# from autils import *\n",
    "# from lab_utils_softmax import plt_softmax\n",
    "np.set_printoptions(precision=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_softmax(z):\n",
    "    ### START CODE HERE ###\n",
    "    ez = np.exp(z)\n",
    "    a = ez/np.sum(ez)\n",
    "    ### END CODE HERE ###\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_random_seed(1234) # for consistent results\n",
    "model = Sequential(\n",
    "    [\n",
    "        ### START CODE HERE ###\n",
    "        tf.keras.layers.InputLayer((X_train.shape[1],)),\n",
    "        tf.keras.layers.Dense(20, activation=\"relu\", name=\"L1\"),\n",
    "        tf.keras.layers.Dense(3, activation=\"softmax\", name=\"L2\")\n",
    "        ### END CODE HERE ###\n",
    "    ], name = \"my_model\"\n",
    ")\n",
    "# model.compile(\n",
    "#     loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "#     optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine Layer Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[layer1, layer2] = model.layers\n",
    "#### Examine Weights shapes\n",
    "W1,b1 = layer1.get_weights()\n",
    "W2,b2 = layer2.get_weights()\n",
    "print(f\"W1 shape = {W1.shape}, b1 shape = {b1.shape}\")\n",
    "print(f\"W2 shape = {W2.shape}, b2 shape = {b2.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.001),\n",
    ")\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "#y_train = [Age<8, Age>=8 && Age<15, Age>15]\n",
    "#y_train_classification=['young','middle-age','old']\n",
    "#y_train_encoded = [2,0,1]\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train_encoded,\n",
    "    validation_data=(X_val_scaled, y_val_encoded),\n",
    "    epochs=30,\n",
    "    batch_size=32, \n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss with SGD')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_model(num_neurons):\n",
    "#     model_2 = Sequential([\n",
    "#         tf.keras.layers.InputLayer((X_train.shape[1],)),\n",
    "#         tf.keras.layers.Dense(num_neurons, activation=\"relu\", name=\"L1\"),\n",
    "#         tf.keras.layers.Dense(3, activation=\"softmax\", name=\"L2\")\n",
    "#     ], name=\"my_model_2\")\n",
    "\n",
    "#     model_2.compile(\n",
    "#          loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "#          optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "#     )\n",
    "\n",
    "#     return model_2\n",
    "# neuron_configs = [5, 10, 20, 30, 50]\n",
    "# validation_losses = []\n",
    "\n",
    "\n",
    "# for num_neurons in neuron_configs:\n",
    "#     model_2 = build_model(num_neurons)\n",
    "#     #using early stopping to automatically stop training when the validation loss stops improving. This can prevent overfitting. \n",
    "#     early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "#     history = model_2.fit(X_train_scaled, y_train_encoded, validation_data=(X_val_scaled, y_val_encoded), epochs=30, batch_size=32, callbacks=[early_stopping])\n",
    "#     # Evaluate and print performance metrics\n",
    "#     eval_metrics = model_2.evaluate(X_val_scaled, y_val_encoded)\n",
    "#     validation_loss = eval_metrics\n",
    "#     validation_losses.append((num_neurons, validation_loss))\n",
    "\n",
    "# # Sort and print validation losses\n",
    "# sorted_losses = sorted(validation_losses, key=lambda x: x[1])\n",
    "# for neurons, loss in sorted_losses:\n",
    "#     print(f\"Neurons: {neurons}, Validation Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#y_train = [Age<8, Age>=8 && Age<15, Age>15]\n",
    "#y_train_classification=['young','middle-age','old']\n",
    "#y_train_encoded = [2,0,1]\n",
    "\n",
    "age_of_index = X_test_scaled[300]\n",
    "prediction = model.predict(age_of_index.reshape(1,11))  # prediction\n",
    "print(f\" predicting: \\n{prediction}\")\n",
    "print(f\" Largest Prediction index: {np.argmax(prediction)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability of output with SoftMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction_p = tf.nn.softmax(prediction)\n",
    "\n",
    "# with tf.compat.v1.Session() as sess:\n",
    "#     prediction_p_np = prediction_p.eval()\n",
    "\n",
    "# print(f\"Probability vector:\\n{prediction_p_np}\")\n",
    "# print(f\"Total of predictions: {np.sum(prediction_p_np):0.3f}\")\n",
    "\n",
    "\n",
    "# predicted_class = np.argmax(prediction_p_np)\n",
    "# print(f\"Predicted Class Index: {predicted_class}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unmatched Prediction and Real Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(X_test_scaled)  \n",
    "# Get the predicted class labels\n",
    "predicted_classes = np.argmax(y_pred, axis=1)\n",
    "# Find indices where predictions don't match true labels\n",
    "incorrect_indices = np.where(predicted_classes != y_test_encoded)[0]\n",
    "# Store incorrect predictions for later printing\n",
    "incorrect_predictions = []\n",
    "# Print out the ages and corresponding predictions for the incorrect instances\n",
    "for index in incorrect_indices:\n",
    "    age = y_test_encoded[index]\n",
    "    prediction = predicted_classes[index]\n",
    "    incorrect_predictions.append((index, age, prediction))\n",
    "    print(f\"Index: {index}, True Age: {age}, Predicted Age: {prediction}\")\n",
    "# Calculate accuracy\n",
    "accuracy = np.sum(predicted_classes == y_test_encoded) / len(y_test_encoded)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Print detailed information about incorrect predictions\n",
    "# print(\"\\nIncorrect Predictions:\")\n",
    "# for index, true_age, predicted_age in incorrect_predictions:\n",
    "#     print(f\"Index: {index}, True Age: {true_age}, Predicted Age: {predicted_age}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_test_encoded, predicted_classes)\n",
    "#y_train = [Age<8, Age>=8 && Age<15, Age>15]\n",
    "#y_train_classification=['young','middle-age','old']\n",
    "#y_train_encoded = [2,0,1]\n",
    "# Plot confusion matrix using seaborn\n",
    "plt.figure(figsize=(4,3))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Reds', cbar=False,\n",
    "            xticklabels=['middle-age', 'old', 'young'],\n",
    "            yticklabels=['middle-age', 'old', 'young'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix with SGD')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eltajenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
