{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "551a4fc6",
   "metadata": {},
   "source": [
    "# Data Preprocessing and Splitting for Abalone Dataset\n",
    "\n",
    "This notebook covers the steps for preprocessing the abalone dataset and splitting it into training, testing, and validation sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c2485511",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder,LabelEncoder\n",
    "from data_loader import load_abalone_data\n",
    "import numpy as np\n",
    "\n",
    "abalone_df = load_abalone_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf397b3",
   "metadata": {},
   "source": [
    "## One-Hot Encoding the 'Sex' Column\n",
    "\n",
    "The 'Sex' column is a categorical feature and needs to be converted into a numerical format for machine learning algorithms. We use one-hot encoding to achieve this, resulting in separate columns for each category with binary values (0 or 1).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a3ff1f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# One-hot encode the 'Sex' column\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "sex_encoded = encoder.fit_transform(abalone_df[['Sex']])\n",
    "sex_encoded_df = pd.DataFrame(sex_encoded, columns=encoder.get_feature_names_out(['Sex']))\n",
    "\n",
    "# Drop the original 'Sex' column and concatenate the encoded one\n",
    "abalone_df = abalone_df.drop('Sex', axis=1)\n",
    "abalone_df = pd.concat([abalone_df, sex_encoded_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895aa80b",
   "metadata": {},
   "source": [
    "## Splitting the Dataset into Features and Target\n",
    "\n",
    "We separate the dataset into features (`X`) and the target variable (`y`). The target variable in our case is 'Rings', which indicates the age of the abalone.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b30b3d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into features (X) and target variable (y)\n",
    "X = abalone_df.drop('Rings', axis=1)\n",
    "y = abalone_df['Rings']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee39a7c",
   "metadata": {},
   "source": [
    "## Splitting the Data into Training, Testing, and Validation Sets\n",
    "\n",
    "We split the data into three parts:\n",
    "1. Training set (80% of the data): Used to train the model.\n",
    "2. Testing set (10% of the data): Used to test the model's performance after training.\n",
    "3. Validation set (10% of the data): Used to fine-tune the model's hyperparameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ed409cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2830    middle_age\n",
      "925          young\n",
      "3845    middle_age\n",
      "547          young\n",
      "2259    middle_age\n",
      "           ...    \n",
      "3444    middle_age\n",
      "466     middle_age\n",
      "3092    middle_age\n",
      "3772    middle_age\n",
      "860          young\n",
      "Name: Rings, Length: 2923, dtype: category\n",
      "Categories (3, object): ['young' < 'middle_age' < 'old']\n",
      "2830    middle_age\n",
      "925          young\n",
      "3845    middle_age\n",
      "547          young\n",
      "2259    middle_age\n",
      "           ...    \n",
      "3444    middle_age\n",
      "466     middle_age\n",
      "3092    middle_age\n",
      "3772    middle_age\n",
      "860          young\n",
      "Name: Rings, Length: 2923, dtype: category\n",
      "Categories (3, object): ['young' < 'middle_age' < 'old']\n",
      "Training set: (2923, 11) (2923,)\n",
      "Testing set: (627, 11) (627,)\n",
      "Validation set: (627, 11) (627,)\n",
      "\n",
      "Training set:\n",
      "      Length  Diameter  Height  Whole weight  Shucked weight  Viscera weight  \\\n",
      "2830   0.525     0.430   0.135        0.8435          0.4325          0.1800   \n",
      "925    0.430     0.325   0.100        0.3645          0.1575          0.0825   \n",
      "3845   0.455     0.350   0.105        0.4160          0.1625          0.0970   \n",
      "547    0.205     0.155   0.045        0.0425          0.0170          0.0055   \n",
      "2259   0.590     0.465   0.160        1.1005          0.5060          0.2525   \n",
      "\n",
      "      Shell weight   Age  Sex_F  Sex_I  Sex_M  \n",
      "2830        0.1815  10.5    1.0    0.0    0.0  \n",
      "925         0.1050   8.5    0.0    1.0    0.0  \n",
      "3845        0.1450  12.5    0.0    0.0    1.0  \n",
      "547         0.0155   8.5    0.0    0.0    1.0  \n",
      "2259        0.2950  14.5    1.0    0.0    0.0  \n",
      "\n",
      "Testing set:\n",
      "      Length  Diameter  Height  Whole weight  Shucked weight  Viscera weight  \\\n",
      "3142   0.215     0.165   0.055        0.0590          0.0265          0.0125   \n",
      "752    0.605     0.460   0.170        1.1220          0.3470          0.3045   \n",
      "1188   0.690     0.540   0.155        1.4540          0.6240          0.3105   \n",
      "3740   0.650     0.500   0.170        1.4045          0.6940          0.3180   \n",
      "2586   0.555     0.425   0.140        0.9630          0.4400          0.2240   \n",
      "\n",
      "      Shell weight   Age  Sex_F  Sex_I  Sex_M  \n",
      "3142        0.0185   6.5    0.0    1.0    0.0  \n",
      "752         0.3150  14.5    1.0    0.0    0.0  \n",
      "1188        0.3900  10.5    1.0    0.0    0.0  \n",
      "3740        0.3235  12.5    1.0    0.0    0.0  \n",
      "2586        0.2400   8.5    1.0    0.0    0.0  \n",
      "\n",
      "Validation set:\n",
      "      Length  Diameter  Height  Whole weight  Shucked weight  Viscera weight  \\\n",
      "2148   0.415     0.310   0.090        0.3245          0.1305          0.0735   \n",
      "2303   0.580     0.455   0.120        0.9400          0.3990          0.2570   \n",
      "270    0.640     0.525   0.215        1.7790          0.4535          0.2855   \n",
      "3409   0.395     0.310   0.095        0.3130          0.1310          0.0720   \n",
      "3654   0.530     0.420   0.140        0.6765          0.2560          0.1855   \n",
      "\n",
      "      Shell weight   Age  Sex_F  Sex_I  Sex_M  \n",
      "2148         0.115   9.5    0.0    0.0    1.0  \n",
      "2303         0.265  12.5    1.0    0.0    0.0  \n",
      "270          0.550  23.5    1.0    0.0    0.0  \n",
      "3409         0.093   8.5    0.0    1.0    0.0  \n",
      "3654         0.208  10.5    0.0    1.0    0.0  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Splitting the dataset into training (80%), and a temporary set (20%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "#Creaing new y_train for classification of age\n",
    "bins = [0, 8, 15, np.inf]\n",
    "labels = ['young', 'middle_age', 'old']\n",
    "\n",
    "# Create the new classification target variable\n",
    "y_train_classification = pd.cut(y_train, bins, labels=labels, right=True)\n",
    "# Print the result\n",
    "print(y_train_classification)\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train_classification)\n",
    "# Print the result\n",
    "print(y_train_encoded)\n",
    "\n",
    "# Splitting the temporary set into testing and validation sets (50% each of the temporary set, 10% each of the total dataset)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Printing the shapes of the resulting sets\n",
    "print('Training set:', X_train.shape, y_train.shape)\n",
    "print('Testing set:', X_test.shape, y_test.shape)\n",
    "print('Validation set:', X_val.shape, y_val.shape)\n",
    "\n",
    "# Printing some rows from each created set\n",
    "print('\\nTraining set:')\n",
    "print(X_train.head())\n",
    "print('\\nTesting set:')\n",
    "print(X_test.head())\n",
    "print('\\nValidation set:')\n",
    "print(X_val.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a104247",
   "metadata": {},
   "source": [
    "## Feature Scaling\n",
    "\n",
    "We scale the features to ensure they contribute equally to the model's performance. This is particularly important for models that are sensitive to the scale of the input data, such as linear regression.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a4950bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 5 rows of the scaled training set:\n",
      " [[-0.00954585  0.20680221 -0.12072394  0.01457825  0.31105444 -0.02098237\n",
      "  -0.42540763 -0.30383887  1.46390258 -0.67933791 -0.75989604]\n",
      " [-0.80318028 -0.85404855 -0.94465076 -0.95900917 -0.9194155  -0.91375895\n",
      "  -0.96974532 -0.92144737 -0.68310557  1.47202148 -0.75989604]\n",
      " [-0.59432912 -0.60146504 -0.82694693 -0.85433328 -0.89704332 -0.78098705\n",
      "  -0.68512431  0.31376963 -0.68310557 -0.67933791  1.31596949]\n",
      " [-2.68284079 -2.57161646 -2.2393929  -1.61348756 -1.54807379 -1.61882353\n",
      "  -1.60658483 -0.92144737 -0.68310557 -0.67933791  1.31596949]\n",
      " [ 0.53346719  0.56041914  0.46779521  0.53694144  0.6399255   0.64287714\n",
      "   0.38220449  0.93137813  1.46390258 -0.67933791 -0.75989604]]\n",
      "\n",
      "First 5 rows of the scaled testing set:\n",
      " [[-2.59930032 -2.47058306 -2.00398524 -1.57995062 -1.50556664 -1.55472675\n",
      "  -1.58523826 -1.53905587 -0.68310557  1.47202148 -0.75989604]\n",
      " [ 0.65877789  0.50990243  0.70320287  0.58064109 -0.07150985  1.11902465\n",
      "   0.524515    0.93137813  1.46390258 -0.67933791 -0.75989604]\n",
      " [ 1.36887186  1.31816968  0.35009138  1.25544489  1.16790897  1.17396475\n",
      "   1.05817939 -0.30383887  1.46390258 -0.67933791 -0.75989604]\n",
      " [ 1.03470999  0.91403606  0.70320287  1.15483408  1.4811195   1.24263987\n",
      "   0.58499696  0.31376963  1.46390258 -0.67933791 -0.75989604]\n",
      " [ 0.24107555  0.15628551 -0.00302011  0.25746697  0.34461272  0.38191168\n",
      "  -0.0091494  -0.92144737  1.46390258 -0.67933791 -0.75989604]]\n",
      "\n",
      "First 5 rows of the scaled validation set:\n",
      " [[-9.28490985e-01 -1.00559866e+00 -1.18005842e+00 -1.04031083e+00\n",
      "  -1.04022528e+00 -9.96169094e-01 -8.98590066e-01 -6.12643122e-01\n",
      "  -6.83105567e-01 -6.79337913e-01  1.31596949e+00]\n",
      " [ 4.49926719e-01  4.59385730e-01 -4.73835436e-01  2.10718517e-01\n",
      "   1.61160833e-01  6.84082213e-01  1.68738731e-01  3.13769628e-01\n",
      "   1.46390258e+00 -6.79337913e-01 -7.59896036e-01]\n",
      " [ 9.51169521e-01  1.16661957e+00  1.76253735e+00  1.91602091e+00\n",
      "   4.05017604e-01  9.45047675e-01  2.19666344e+00  3.71061638e+00\n",
      "   1.46390258e+00 -6.79337913e-01 -7.59896036e-01]\n",
      " [-1.09557192e+00 -1.00559866e+00 -1.06235459e+00 -1.06368506e+00\n",
      "  -1.03798806e+00 -1.00990412e+00 -1.05513162e+00 -9.21447372e-01\n",
      "  -6.83105567e-01  1.47202148e+00 -7.59896036e-01]\n",
      " [ 3.22243847e-02  1.05768807e-01 -3.02011198e-03 -3.24856192e-01\n",
      "  -4.78683540e-01  2.93793877e-02 -2.36846212e-01 -3.03838872e-01\n",
      "  -6.83105567e-01  1.47202148e+00 -7.59896036e-01]]\n"
     ]
    }
   ],
   "source": [
    "# Scaling the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# Printing the first 5 rows of the scaled sets\n",
    "print('\\nFirst 5 rows of the scaled training set:\\n', X_train_scaled[:5])\n",
    "print('\\nFirst 5 rows of the scaled testing set:\\n', X_test_scaled[:5])\n",
    "print('\\nFirst 5 rows of the scaled validation set:\\n', X_val_scaled[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa69a05b",
   "metadata": {},
   "source": [
    "## Verifying the Sizes of the Splits\n",
    "\n",
    "We print the sizes of each split to ensure the data has been divided correctly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "89af784b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set: 2923 samples\n",
      "Testing Set: 627 samples\n",
      "Validation Set: 627 samples\n"
     ]
    }
   ],
   "source": [
    "# Verifying the sizes of the splits\n",
    "print(f\"Training Set: {len(X_train)} samples\")\n",
    "print(f\"Testing Set: {len(X_test)} samples\")\n",
    "print(f\"Validation Set: {len(X_val)} samples\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
